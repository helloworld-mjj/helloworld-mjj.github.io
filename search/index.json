[{"content":"网关功能 这里先梳理一下我们的网关主要的功能。\n请求路由: 这是网关的最核心的功能，将前端的请求聚合到网关进行分发。 熔断限流: 支持单机限流以及分布式限流，并且支持多种限流算法。为了下游服务的安全性，我们必须对部分可能出现大流量的接口进行限流，并对不可用的服务进行熔断防止服务雪崩。 统一鉴权: 在网关层进行统一鉴权，让下游服务更专注于业务代码的编写。 服务监控: 在网关层进行服务的监控，同样可以让下游服务专注于业务代码的编写。 负载均衡: 这也是网关的一个核心功能，需要对多个相同的服务进行负载均衡，保证各个服务器可以分担压力。 灰度发布: 灰度发布旨在提高服务的可用性，在发布新版本时不用停止服务。 目录结构 模块介绍 mGateway-client: 定义了一些注解以及用于将测试服务注册到注册中心\nmGateway-http-server: 定义了一些测试类，结合client模块注册到注册中心方便进行网关测试\nmGateway-common: 此模块为公共模块，定义了一些通用的类\nmGateway-config-center: 定义了配置中心的接口及其基于SPI的实现\nmGateway-register-center: 定义了注册中心的接口及其基于SPI的实现\nmGateway-corn: 此模块为核心模块，包括netty服务器和客户端、过滤器链、上下文的配置等\n核心模块目录介绍 BootStrap: 网关的启动类，启动网关并加载配置和注册订阅服务\nConfig: 网关的配置信息，此类中配置了默认值，网关启动时会从classpath下的gateway.properties文件加载配置\nConfigLoader: 此类定义了加载配置的具体方法和步骤\nContainer: 此类实现了lifeCycle接口，用于管理netty的组件，包括它们的初始化、启动、终止\nnetty: 这个包中定义了一些netty的一些组件，包括netty服务器、netty客户端、Disruptor事件处理、Http请求处理等\nhelper: 这个包中定义了解析request和response的组件，以及异步Http请求客户端\nrequest: 这个包中定义了网关的请求类\nresponse: 这个包中定义了网关的响应类\ndisruptor: 这个包中配置了Disruptor框架\nfilter: 这个包中定义了一系列的过滤器，使用SPI的方式进行加载，包括鉴权过滤器、灰度发布过滤器、限流过滤器、负载均衡过滤器、监控过滤器、路由过滤器等\ncontext: 这个包中定义了网关的上下文对象，所谓上下文就是贯穿了整个网关，包含了解析后的请求和响应\ncache: 这个包中定义了网关的缓存，主要是Caffine实现的本地缓存\n公共模块目录介绍 config: 此包定义了网关的一些配置信息，比如服务定义实体和服务实体，以及路由规则实体和服务映射关系\nconstant: 此包定义了一些常量\nenums: 此包定义了一些枚举类型\nexception: 此包定义了网关中的异常类\nutils: 此包定义了一些工具类，包括对象转换、JWT工具、IP解析等\n功能实现 服务器实现 我们做为网关首先需要可以接收网络请求，这里使用Netty构建服务器，主要得益于Netty的Reactor模型，netty服务器的实现主要在com.gateway.core.netty.NettyHttpServer这个类中。\n主要思路是使用BossEventLoopGroup来管理网络连接，而WorkerEventLoopGroup来管理网络I/O，WorkerEventLoopGroup接收到I/O请求作为生产者生产一个事件交给Disruptor，而使用了一组消费者线程池来处理Disruptor中的事件。\n客户端实现 这里我们基于异步Http客户端DefaultAsycHttpClient结合Netty的EventLoopGroup构建了一个用来转发请求的异步Http客户端，其主要实现在com.gateway.core.netty.NettyHttpClient这个类中。\n请求上下文实现 这里我们首先定义了IContext接口定义了上下文规范。\nBaseContext为上下文的基本实现，定义了上下文的协议、状态、异常、上下文相关参数、以及对应的netty上下文。\nGateContext为网关上下文的实现，继承了BaseContext，并且封装了request和response以及请求规则和相关参数。\n过滤器链实现 所有的过滤器都需要实现Filter接口，启动时会以SPI的方式加载这些过滤器，只需要实现Filter这个接口就可以添加自定义的过滤器。\n每次收到请求时我们都需要一个过滤器链来处理请求，这个过滤器链是根据Rule请求规则构建的，这里为了避免重复对同一种请求重复构建过滤器链，我们对过滤器链添加了缓存。同时我们需要一个过滤器链工厂来构建过滤器链，这个工厂不需要重复构建多个，因为这个工厂可以生产多个过滤器链，所以引入工厂模式和单例模式构建这个过滤器工厂用来生产过滤器链。\n实际上我们的网关的核心功能也就是一些过滤器的集合。\n鉴权过滤器 使用JWT鉴权\n限流过滤器 支持滑动时间窗口限流、令牌桶限流、漏斗限流\n负载均衡过滤器 支持随机负载、轮询、加权轮询\n监控过滤器 使用prompt进行监控\n灰度发布过滤器 路由过滤器 使用Hystrix进行熔断机制\n——更多细节正在梳理中\u0026hellip;\n","date":"2024-05-29T17:30:58+08:00","permalink":"https://helloworld-mjj.github.io/p/%E6%89%8B%E5%86%99%E7%BD%91%E5%85%B3%E6%96%87%E6%A1%A3/","title":"手写网关文档"},{"content":"Docker配置镜像加速 目前主流 Linux 发行版均已使用 systemd 进行服务管理，这里介绍如何在使用 systemd 的 Linux 发行版中配置镜像加速器。\n请首先执行以下命令，查看是否在 docker.service 文件中配置过镜像地址。\n1 $ systemctl cat docker | grep \u0026#39;\\-\\-registry\\-mirror\u0026#39; 如果该命令有输出，那么请执行 $ systemctl cat docker 查看 ExecStart= 出现的位置，修改对应的文件内容去掉 \u0026ndash;registry-mirror 参数及其值，并按接下来的步骤进行配置。\n如果以上命令没有任何输出，那么就可以在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件）：\n1 2 3 4 5 6 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://mirror.baidubce.com\u0026#34; ] } 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。\n1 2 $ sudo systemctl daemon-reload $ sudo systemctl restart docker Docker构建Redis集群（主从模式） 创建Redis网络 1 2 3 docker network ls #查看网络 docker network create redis --subnet 192.168.100.0/24 #创建网络 docker network inspect redis #查看网络配置信息 创建Redis配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 for port in $(seq 1 6); \\ do \\ mkdir -p /mydata/redis/node-${port}/conf touch /mydata/redis/node-${port}/conf/redis.conf cat \u0026lt;\u0026lt; EOF \u0026gt;/mydata/redis/node-${port}/conf/redis.conf port 6379 bind 0.0.0.0 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 cluster-announce-ip 192.168.100.1${port} cluster-announce-port 6379 cluster-announce-bus-port 16379 appendonly yes EOF done 启动Redis容器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # 第一个节点配置命令 docker run -p 6371:6379 -p 16371:16379 --name redis-01 \\ -v /mydata/redis/node-1/data:/data \\ -v /mydata/redis/node-1/conf/redis.conf:/etc/redis/redis.conf \\ -d --net redis --ip 192.168.100.11 redis:latest redis-server /etc/redis/redis.conf # 命令参数解释： # -p 6371:6379 对外端口 # -p 16371:16379 Redis内部通信端口 # -v /mydata/redis/node-1/data:/data 绑定挂载卷（容器内外挂载路径） # -d 在后台运行容器并打印容器ID # --net redis 使用自定义redis网络 # --ip 指定IP地址 # redis:latest 指定Redis版本号 # 第二个节点配置命令 docker run -p 6372:6379 -p 16372:16379 --name redis-02 \\ -v /mydata/redis/node-2/data:/data \\ -v /mydata/redis/node-2/conf/redis.conf:/etc/redis/redis.conf \\ -d --net redis --ip 192.168.100.12 redis:latest redis-server /etc/redis/redis.conf # 第三个节点配置命令 docker run -p 6373:6379 -p 16373:16379 --name redis-03 \\ -v /mydata/redis/node-3/data:/data \\ -v /mydata/redis/node-3/conf/redis.conf:/etc/redis/redis.conf \\ -d --net redis --ip 192.168.100.13 redis:latest redis-server /etc/redis/redis.conf # 第四个节点配置命令 docker run -p 6374:6379 -p 16374:16379 --name redis-04 \\ -v /mydata/redis/node-4/data:/data \\ -v /mydata/redis/node-4/conf/redis.conf:/etc/redis/redis.conf \\ -d --net redis --ip 192.168.100.14 redis:latest redis-server /etc/redis/redis.conf # 第五个节点配置命令 docker run -p 6375:6379 -p 16375:16379 --name redis-05 \\ -v /mydata/redis/node-5/data:/data \\ -v /mydata/redis/node-5/conf/redis.conf:/etc/redis/redis.conf \\ -d --net redis --ip 192.168.100.15 redis:latest redis-server /etc/redis/redis.conf # 第六个节点配置命令 docker run -p 6376:6379 -p 16376:16379 --name redis-06 \\ -v /mydata/redis/node-6/data:/data \\ -v /mydata/redis/node-6/conf/redis.conf:/etc/redis/redis.conf \\ -d --net redis --ip 192.168.100.16 redis:latest redis-server /etc/redis/redis.conf 创建Redis集群 1 2 docker exec -it redis-01 /bin/sh redis-cli --cluster create 192.168.100.11:6379 192.168.100.12:6379 192.168.100.13:6379 192.168.100.14:6379 192.168.100.15:6379 192.168.100.16:6379 --cluster-replicas 1 查看Redis集群 1 2 3 4 # 进入集群 redis-cli -c # 查看集群内节点 cluster nodes 测试Redis集群高可用 1 2 3 4 # 查看节点 docker ps # 停止redis-03节点 docker stop redis-03 1 2 3 4 5 6 7 # 重新启动redis-03节点 docker start redis-03 docker exec -it redis-01 /bin/sh # 查看集群 redis-cli -c cluster info cluster nodes Docker安装Elasticsearch单机 1 2 3 4 5 6 7 8 docker pull elasticsearch:7.9.3 mkdir /mydata/es/data mkdir /mydata/es/config mkdir /mydata/es/plugins echo \u0026#34;http.host: 0.0.0.0\u0026#34; \u0026gt;\u0026gt; /mydata/es/config/elasticsearch.yml sudo chmod 777 /mydata/es/data sudo chmod 777 /mydata/es/plugins sudo chmod 777 /mydata/es/elasticsearch.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 docker run -d \\ --name es \\ -e \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34; \\ -e \u0026#34;discovery.type=single-node\u0026#34; \\ -v /mydata/es/data:/usr/share/elasticsearch/data \\ -v /mydata/es/plugins:/usr/share/elasticsearch/plugins \\ -v /mydata/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ --privileged \\ -p 9200:9200 \\ -p 9300:9300 \\ elasticsearch:7.9.3 # -e \u0026#34;cluster.name=es-docker-cluster\u0026#34;：设置集群名称 # -e \u0026#34;http.host=0.0.0.0\u0026#34;：监听的地址，可以外网访问 # -e \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34;：内存大小 # -e \u0026#34;discovery.type=single-node\u0026#34;：非集群模式 # -v /mydata/es/data:/usr/share/elasticsearch/data：挂载逻辑卷，绑定elasticsearch的数据目录 # -v /mydata/es/logs:/usr/share/elasticsearch/logs：挂载逻辑卷，绑定elasticsearch的日志目录 # -v /mydata/es/plugins:/usr/share/elasticsearch/plugins：挂载逻辑卷，绑定elasticsearch的插件目录 # --privileged：授予逻辑卷访问权 # --network elasticsearch ：加入一个名为elasticsearch的网络中 # -p 9200:9200：端口映射配置 1 2 3 4 5 6 7 8 9 10 11 docker pull kibana:7.9.3 docker run --name kibana -e ELASTICSEARCH_HOSTS=http://127.0.0.1:9200 -p 5601:5601 -d kibana:7.9.3 # 进入容器修改相应内容 server.port: 5601 server.host: 0.0.0.0 elasticsearch.hosts: [ \u0026#34;http://127.0.0.1:9200\u0026#34; ] i18n.locale: \u0026#34;Zh-CN\u0026#34; 然后访问页面 http://127.0.0.1:5601/app/kibana # 暂未解决 Docker安装Nginx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 docker pull nginx mkdir -p /mydata/nginx/data mkdir -p /mydata/nginx/log mkdir -p /mydata/nginx/html mkdir -p /mydata/nginx/conf # 容器中的 nginx.conf 文件和 conf.d 文件夹复制到宿主机 # 生成容器 docker run --name nginx -p 80:80 -d nginx # 将容器nginx.conf文件复制到宿主机 docker cp nginx:/etc/nginx/nginx.conf /mydata/nginx/conf/nginx.conf # 将容器conf.d文件夹下内容复制到宿主机 docker cp nginx:/etc/nginx/conf.d /mydata/nginx/conf/conf.d # 将容器中的html文件夹复制到宿主机 docker cp nginx:/usr/share/nginx/html /mydata/nginx/ # 删除正在运行的nginx容器 docker rm -f nginx docker run \\ -p 80:80 \\ --name nginx \\ --net host \\ -v /mydata/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \\ -v /mydata/nginx/conf/conf.d:/etc/nginx/conf.d \\ -v /mydata/nginx/log:/var/log/nginx \\ -v /mydata/nginx/html:/usr/share/nginx/html \\ -d nginx:latest 安装Docker-compose 1 2 3 4 5 https://github.com/docker/compose #下载最新版本 mv /data/docker-compose-Linux-x86_64 /usr/local/bin/docker-compose chmod 777 /usr/local/bin/docker-compose docker-compose -v Docker-compose安装MySQL 1 2 3 4 5 6 7 8 9 10 11 12 13 version: \u0026#39;2\u0026#39; services: mysql: image: mysql:latest environment: MYSQL_ROOT_PASSWORD: mysql restart: always container_name: mysql volumes: - /mydata/mysql/db:/var/lib/mysql - /mydata/mysql/logs:/var/log/mysql ports: - 3306:3306 Docker-compose安装RabbitMQ 1 2 3 4 5 6 7 8 9 10 11 12 13 # docker-compose.yml version: \u0026#39;2\u0026#39; services: rabbitmq: image: rabbitmq:latest restart: always container_name: rabbitmq ports: - 5672:5672 - 15672:15672 volumes: - /mydata/rabbitmq/data/:/var/lib/rabbitmq/ - /mydata/rabbitmq/log/:/var/log/rabbitmq/log/ 1 2 3 4 # 开启可视化插件 docker exec -it rabbitmq /bin/bash cd /opt/rabbitmq/sbin ./rabbitmq-plugins enable rabbitmq_management ","date":"2024-05-25T17:30:58+08:00","permalink":"https://helloworld-mjj.github.io/p/docker%E7%AC%94%E8%AE%B0/","title":"Docker笔记"},{"content":"安装Hugo 我使用的ubuntu系统，但是这个命令下载hugo下载下来不是最新的版本，所以有一些坑。\n1 sudo apt install hugo 我使用的是下面这个命令：\n1 sudo snap install hugo 使用这个命令下载之后还需要将snap加入环境变量。\n新建Site 使用命令\n1 hugo new site myblog 新建一个网站文件夹。\n下载主题 我用的这个stack主题\n配置主题 将stack文件夹中的config.yaml和content文件夹拷贝myblog根目录。\n本地启动 使用命令在本地启动：\n1 hugo server -D ","date":"2024-05-25T17:30:58+08:00","permalink":"https://helloworld-mjj.github.io/p/%E6%9E%84%E5%BB%BA%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/","title":"构建我的博客网站"},{"content":"API网关回顾 主要功能 路由转发：通过路由功能将请求转发到目标服务。 负载均衡：多个服务之间的负载均衡。 统一鉴权：对用户的身份进行统一的验证。 协议转换：通过协议转换整合REST、AMQP、RPC等不同的协议。 指标监控：网关对发送到服务的请求进行监控。 限流熔断：在网关层面对请求进行限流，并且当服务发生故障时有响应的处理策略，使用户体验良好。 黑白名单：过滤请求，拦截异常的请求信息。 灰度发布：可以在多个部署下实现灰度发布。 流量染色：可以在进出流量时抓住时机。 20：微服务网管作为自己的日志收集和收集器，对服务URL粒度的日志请求和响应信息就进行拦截。 常见的API网关 Nginx Zuul SpringCloud Gateway Kong OpenRestry Traefik ","date":"2024-05-25T17:30:58+08:00","permalink":"https://helloworld-mjj.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3%E5%AF%B9%E6%AF%94/","title":"微服务网关对比"}]